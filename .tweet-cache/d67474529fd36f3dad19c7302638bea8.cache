{"url":"https://twitter.com/RobertRosenba14/status/1517465854157500419","author_name":"Robert Rosenbaum","author_url":"https://twitter.com/RobertRosenba14","html":"<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">How good is a gradient?<br><br>The top histogram shows the change in loss from 1000 random weight updates with a fixed norm. The bottom compares this histogram to the change in loss from a gradient descent step with the same norm.<br><br>It&#39;s 280 standard deviations away! <a href=\"https://t.co/iJ2SSESEJ0\">pic.twitter.com/iJ2SSESEJ0</a></p>&mdash; Robert Rosenbaum (@RobertRosenba14) <a href=\"https://twitter.com/RobertRosenba14/status/1517465854157500419?ref_src=twsrc%5Etfw\">April 22, 2022</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https://twitter.com","version":"1.0"}